[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"

[project]
name = "skyrl-tx"
dynamic = ["version"]
description = "Unified API for training and inference"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "datasets>=4.0.0",
    "pillow>=11.3.0",
    "rich>=14.1.0",
    "safetensors>=0.6.2",
    "tokenizers>=0.21.2",
    "transformers>=4.56.1,<5",
    "typer>=0.17.4",
    # "wandb>=0.22.0",
    "peft",
    "hf_transfer",
    "cloudpathlib>=0.23.0",
]

[project.optional-dependencies]
gpu = [
    "jax[cuda12]>=0.7.2; sys_platform == 'linux'",
]

tpu = [
    "jax[tpu]>=0.7.2; sys_platform == 'linux'",
]

tinker = [
    "tinker>=0.3.0",
    "fastapi[standard]",
    "sqlmodel",
    "sqlalchemy[asyncio]",
    "aiosqlite",
    "asyncpg",
    "psycopg2-binary",
]

aws = [
    "cloudpathlib[s3]",
]

gcp = [
    "cloudpathlib[gs]",
]

azure = [
    "cloudpathlib[azure]",
]

# The extras "jax", "fsdp", and "megatron" are the dependencies the
# engine needs for --backend="jax", --backend="fsdp", and --backend="megatron",
# respectively.

jax = [
    "jax>=0.8,<1.0",
    "jax[cuda12]>=0.7.2; sys_platform == 'linux'",
    "flax>=0.12.2",
    "optax>=0.2.5",
]

fsdp = [
    # We currently need the extra pin on the python version
    # here since skyrl-train pins on python version 3.12,
    # hopefully in the future we can remove that.
    # skyrl-train[vllm] requires CUDA packages which are Linux-only.
    "skyrl-train[vllm]; python_version == '3.12' and sys_platform == 'linux'",
]

megatron = [
    "skyrl-train[mcore]; python_version == '3.12' and sys_platform == 'linux'",
]

dev = [
    "mkdocs",
    "mkdocs-material",
    "pytest",
    "pytest-forked",
    "torch",
    "ty",
    "cloudpathlib[s3]",
    "alembic",
]

[tool.setuptools]
include-package-data = true

[tool.setuptools.dynamic]
version = {attr = "tx.__version__"}

[project.scripts]
tx = "tx.run.main:app"

# The following is for supporting the skyrl-train dependency

[tool.uv]
# Resolve for both Linux (production) and macOS (dev)
required-environments = [
    "sys_platform == 'linux'",
    "sys_platform == 'darwin' and platform_machine == 'arm64'",
]

constraint-dependencies = [
    "flashinfer-jit-cache==0.5.3",
]
# each backend should have separate dependencies that can potentially clash
# megatron also clashes with the jax dependency from gpu and tpu extras
conflicts = [
    [
        { extra = "jax" },
        { extra = "megatron" },
        { extra = "fsdp" }
    ],
    [
        { extra = "megatron" },
        { extra = "gpu" },
        { extra = "tpu" },
    ]
]
# disable build isolation for megatron related dependencies 
no-build-isolation-package = [
    "transformer-engine-torch",
    "transformer-engine",
    "nv-grouped-gemm",
]
# override unnecessary dependencies and pin versions to override Megatron-Bridge
# unppinned dependencies
override-dependencies = [
    "nvidia-resiliency-ext; sys_platform == 'never'",
    "mamba-ssm; sys_platform == 'never'",
    "causal-conv1d; sys_platform == 'never'",
    "transformer-engine[pytorch]==2.10.0; sys_platform == 'linux'",
    "megatron-core==0.15.0; sys_platform == 'linux'",
]
[tool.uv.extra-build-dependencies]
flash-attn = [{requirement = "torch", match-runtime = true}]
transformer-engine = [{requirement = "torch", match-runtime = true}, "build_tools", "ninja"]
transformer-engine-torch = [{requirement = "torch", match-runtime = true}, "build_tools", "ninja"]

[tool.uv.extra-build-variables]
flash-attn = { FLASH_ATTENTION_SKIP_CUDA_BUILD = "TRUE"}

[[tool.uv.index]]
name = "pytorch-cu128"
url = "https://download.pytorch.org/whl/cu128"
explicit = true

[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true

[tool.uv.sources]
# For now, just always use the current main branch, later it will be better to pin it to a released version. For development, you
# can set it to your own development branch.
skyrl-train = { git = "https://github.com/NovaSky-AI/SkyRL", subdirectory = "skyrl-train" }
# Use CUDA torch on Linux, CPU torch on macOS (must match skyrl-train config)
torch = [
    { index = "pytorch-cu128", marker = "sys_platform == 'linux'" },
    { index = "pytorch-cpu", marker = "sys_platform == 'darwin'" },
]
torchvision = [
    { index = "pytorch-cu128", marker = "sys_platform == 'linux'" },
    { index = "pytorch-cpu", marker = "sys_platform == 'darwin'" },
]
# pin megatron bridge commit to fix for MoE + LoRA merging. Update this when an official release is cut
megatron-bridge = {git = "https://github.com/NVIDIA-NeMo/Megatron-Bridge", rev = "04e370eedf8cc44a812189a19f2171d90555c07a", marker = "sys_platform == 'linux'"}
